{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images file path\n",
    "train_root_path = \"./dataset/train\"\n",
    "test_root_path = \"./dataset/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train images and labels\n",
    "train_names = os.listdir(train_root_path)\n",
    "train_images = []\n",
    "train_images_class_id = []\n",
    "for index, name in enumerate(train_names):\n",
    "    curdir = os.path.join(train_root_path, name)\n",
    "    for path in os.listdir(curdir):\n",
    "        img = cv2.imread(os.path.join(curdir, path))\n",
    "        img_array = np.array(img)\n",
    "        train_images.append(img_array)\n",
    "        train_images_class_id.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect faces and filter train images\n",
    "detector = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "filtered_train_images = []\n",
    "filtered_train_images_id = []\n",
    "for i, image in enumerate(train_images):\n",
    "    # grayscaling\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # apply gaussian\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    # detect faces\n",
    "    faces = detector.detectMultiScale(gray, scaleFactor=1.07, minNeighbors=15)\n",
    "\n",
    "    # only valid if there's 1 face detected\n",
    "    if(len(faces) == 1):\n",
    "        (x,y,w,h) = faces[0]\n",
    "        cropped = gray[y:y+h, x:x+w]\n",
    "        filtered_train_images.append(cropped)\n",
    "        filtered_train_images_id.append(train_images_class_id[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train face recognizer\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(filtered_train_images, np.array(filtered_train_images_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test images\n",
    "test_images = []\n",
    "\n",
    "for path in os.listdir(test_root_path):\n",
    "    img = cv2.imread(os.path.join(test_root_path, path))\n",
    "    img_array = np.array(img)\n",
    "    test_images.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect faces and filter test images\n",
    "filtered_test_images = []\n",
    "test_image_rects = []\n",
    "\n",
    "for images in test_images:\n",
    "    # grayscaling\n",
    "    gray = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n",
    "    # apply gaussian\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    # detect faces\n",
    "    faces = detector.detectMultiScale(gray, scaleFactor=1.07, minNeighbors=15)\n",
    "\n",
    "    if(len(faces) == 1):\n",
    "        (x,y,w,h) = faces[0]\n",
    "        crop_img = gray[y:y+h, x:x+w]\n",
    "        filtered_test_images.append(crop_img)\n",
    "        test_image_rects.append(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "predictions = []\n",
    "\n",
    "for img in filtered_test_images:\n",
    "    res, loss = face_recognizer.predict(img)\n",
    "    loss = math.floor(loss * 100) / 100\n",
    "    predictions.append((res, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show prediction results\n",
    "drawn_test_images = []\n",
    "size = 200\n",
    "for img, rect, (prediction, loss) in zip(test_images, test_image_rects, predictions):\n",
    "    (x, y, w, h) = (rect[0])\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "    resized = cv2.resize(img, (size, size))\n",
    "    text = train_names[prediction]\n",
    "    lossText = str(loss)\n",
    "    cv2.putText(resized, text, (10,20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1)\n",
    "    cv2.putText(resized, lossText, (100,20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1)\n",
    "    \n",
    "    drawn_test_images.append(resized)\n",
    "\n",
    "# combine all images\n",
    "combined_image = cv2.hconcat(drawn_test_images)\n",
    "cv2.imshow('img', combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}